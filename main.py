# ... –≤–∞—à–∏ –∏–º–ø–æ—Ä—Ç—ã ...
import logging
import os
import aiohttp
import asyncio
import time
from pathlib import Path
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message, FSInputFile
from aiogram import Router, F
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.utils.keyboard import ReplyKeyboardBuilder
from openai import AsyncOpenAI
from dotenv import load_dotenv
from aiogram.fsm.storage.memory import MemoryStorage

# >>> ADD: –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º pydub –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏ –Ω–∞—à –º–æ–¥—É–ª—å voice
from pydub import AudioSegment
import voice_async
from main2 import ai_response

# ---

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)

load_dotenv()

BASE_DIR = Path(__file__).parent.parent
DATA_DIR = os.path.abspath(os.path.join(os.getcwd(), "data"))
DOWNLOADS_DIR = os.path.abspath(os.path.join(os.getcwd(), "downloads"))
AUDIO_DIR = os.path.abspath(os.path.join(os.getcwd(), "audio"))  # >>> ADD

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(DOWNLOADS_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)  # >>> ADD

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
API_KEY = os.getenv("API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")
BASE_WEATHER_URL = "https://api.openweathermap.org/data/2.5/weather"

if not TELEGRAM_BOT_TOKEN:
    logging.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)
else:
    logging.info("‚úÖ TELEGRAM_BOT_TOKEN —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

if not WEATHER_API_KEY:
    logging.warning("‚ö†Ô∏è WEATHER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–≥–æ–¥—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã.")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
router = Router()

client = AsyncOpenAI(
    api_key=API_KEY,
    base_url="https://api.openai.com/v1",
)

user_data = {}

# >>> ADD: –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ mp3 -> ogg (opus)
def mp3_to_ogg_opus(mp3_path: str, ogg_path: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç mp3 –≤ ogg (Opus) –¥–ª—è voice-—Å–æ–æ–±—â–µ–Ω–∏—è Telegram.
    –¢—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ ffmpeg –≤ —Å–∏—Å—Ç–µ–º–µ.
    """
    audio = AudioSegment.from_file(mp3_path, format="mp3")
    # Telegram —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç ~48kbps opus –¥–ª—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö, –Ω–æ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–æ–≥–æ.
    audio.export(ogg_path, format="ogg", codec="libopus", bitrate="48k")
    return ogg_path
# ---

def restore_user_data():
    """–í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏–∑ —Ñ–∞–π–ª–æ–≤"""
    for file_name in os.listdir(DATA_DIR):
        if not file_name.endswith('.txt'):
            continue
        try:
            parts = file_name.replace('.txt', '').split('_')
            if len(parts) != 2:
                continue
            data_type, user_id_str = parts
            user_id = int(user_id_str)
            file_path = os.path.join(DATA_DIR, file_name)
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if user_id not in user_data:
                user_data[user_id] = {"knowledge": "", "instruction": ""}
            user_data[user_id][data_type] = content
            logging.info(f"–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è user_id={user_id}, type={data_type}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏–∑ —Ñ–∞–π–ª–∞ {file_name}: {e}")

def process_text_file(file_path):
    # ... –∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ ...
    pass

def save_user_data(user_id: int, data_type: str, content: str):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ñ–∞–π–ª"""
    if not content.strip():
        logging.warning("–ü–æ–ø—ã—Ç–∫–∞ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ.")
        return

    file_path = os.path.join(DATA_DIR, f"{data_type}_{user_id}.txt")
    try:
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
        logging.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {file_path}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª {file_path}: {e}")

def load_user_data(user_id: int, data_type: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ —Ñ–∞–π–ª–∞"""
    file_path = os.path.join(DATA_DIR, f"{data_type}_{user_id}.txt")
    if os.path.exists(file_path):
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
            logging.info(f"–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {file_path}")
            return content
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file_path}: {e}")
    return ""

# --- –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã ---
def main_keyboard():
    builder = ReplyKeyboardBuilder()
    builder.add(types.KeyboardButton(text="üéôÔ∏è –û–∑–≤—É—á–∫–∞"))
    builder.add(types.KeyboardButton(text="üå§Ô∏è –ü–æ–≥–æ–¥–∞"))
    builder.add(types.KeyboardButton(text="üåç –ü–µ—Ä–µ–≤–æ–¥"))
    return builder.as_markup(resize_keyboard=True)

def cancel_keyboard():
    builder = ReplyKeyboardBuilder()
    builder.add(types.KeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞"))
    return builder.as_markup(resize_keyboard=True)

# >>> ADD: –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞ (reply)
def voices_keyboard(voices: list[dict]):
    """
    voices: [{'name': str, 'id': str}, ...]
    """
    builder = ReplyKeyboardBuilder()
    # –†–∞–∑–ª–æ–∂–∏–º –∫–Ω–æ–ø–∫–∏ –ø–æ 2-3 –≤ —Ä—è–¥:
    for v in voices:
        # –ù–∞ —Å–ª—É—á–∞–π –∫–æ–ª–ª–∏–∑–∏–π –∏–º—ë–Ω –¥–æ–±–∞–≤–∏–º —Ö–≤–æ—Å—Ç –∏–∑ id
        name = v["name"]
        builder.add(types.KeyboardButton(text=name))
    builder.add(types.KeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞"))
    builder.adjust(2)
    return builder.as_markup(resize_keyboard=True)
# ---

# --- FSM States ---
class Form(StatesGroup):
    weather = State()
    translate = State()

# >>> ADD: —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è TTS
class TTS(StatesGroup):
    choosing_voice = State()
    waiting_text = State()
# ---

@router.message(Command("start"))
async def start_command(message: Message, state: FSMContext):
    try:
        # –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–∞ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—ã–±–æ—Ä
        voices = await voice_async.get_all_voices()  # [{'name','id'},...]
        # –°–æ—Ö—Ä–∞–Ω–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–º—è->id –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —é–∑–µ—Ä–∞
        await state.update_data(voices_map={v["name"]: v["id"] for v in voices})
        await state.set_state(TTS.choosing_voice)

        photo = None
        try:
            photo = FSInputFile('img/–§–æ—Ç–æ–ë–æ—Ç1.jpg')
        except Exception:
            pass

        text = (
            "–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à AI-–ø–æ–º–æ—â–Ω–∏–∫. –í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏, –∞ –∑–∞—Ç–µ–º –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç.\n\n"
            "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:"
        )

        if photo:
            await message.answer_photo(
                photo=photo,
                caption=text,
                reply_markup=voices_keyboard(voices)
            )
        else:
            await message.answer(text, reply_markup=voices_keyboard(voices))
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ /start: {e}")
        await message.answer("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?", reply_markup=main_keyboard())

# >>> ADD: –æ—Ç–¥–µ–ª—å–Ω–∞—è –∫–Ω–æ–ø–∫–∞ –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é –¥–ª—è –æ–∑–≤—É—á–∫–∏
@dp.message(F.text == "üéôÔ∏è –û–∑–≤—É—á–∫–∞")
async def tts_entry(message: Message, state: FSMContext):
    try:
        voices = await voice_async.get_all_voices()
        await state.update_data(voices_map={v["name"]: v["id"] for v in voices})
        await state.set_state(TTS.choosing_voice)
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:", reply_markup=voices_keyboard(voices))
    except Exception as e:
        logging.error(f"TTS entry error: {e}")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤.", reply_markup=main_keyboard())
# ---

@dp.message(F.document)
async def handle_document(message: Message):
    if not message.document.file_name.endswith('.txt'):
        await message.answer("‚ö† –ü—Ä–∏–Ω–∏–º–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (.txt)")
        return

    try:
        file_info = await bot.get_file(message.document.file_id)
        file_name = f"{message.from_user.id}_{file_info.file_path.split('/')[-1]}"
        file_path = Path(DOWNLOADS_DIR) / file_name
        await bot.download_file(file_info.file_path, destination=file_path)

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()

        if not content:
            await message.answer("‚ùå –§–∞–π–ª –ø—É—Å—Ç–æ–π.")
            return

        user_id = message.from_user.id
        filename = message.document.file_name.lower()

        if "–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è" in filename:
            data_type = "instruction"
            reply_text = "‚úÖ –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∞!"
        elif "–±–∞–∑–∞" in filename:
            data_type = "knowledge"
            reply_text = "‚úÖ –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –æ–±–Ω–æ–≤–ª–µ–Ω–∞!"
        else:
            await message.answer("‚ö† –ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è' –∏–ª–∏ '–±–∞–∑–∞'.")
            return

        if user_id not in user_data:
            user_data[user_id] = {"knowledge": "", "instruction": ""}
        user_data[user_id][data_type] = content
        save_user_data(user_id, data_type, content)

        await message.answer(reply_text)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
        await message.answer("‚ö† –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞.")

@dp.message(Command("instruction"))
async def show_instruction(message: Message):
    user_id = message.from_user.id
    instruction = user_data.get(user_id, {}).get("instruction", "–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
    await message.answer(f"–í–∞—à–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:\n{instruction}")

@dp.message(Command("knowledge"))
async def show_knowledge(message: Message):
    user_id = message.from_user.id
    knowledge = user_data.get(user_id, {}).get("knowledge", "–ù–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
    await message.answer(f"–í–∞—à–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n{knowledge}")

@dp.message(F.text == "‚ùå –û—Ç–º–µ–Ω–∞")
async def cancel_handler(message: Message, state: FSMContext):
    await state.clear()
    await message.answer("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ", reply_markup=main_keyboard())

@dp.message(F.text == "üå§Ô∏è –ü–æ–≥–æ–¥–∞")
async def weather_handler(message: Message, state: FSMContext):
    await state.set_state(Form.weather)
    await message.answer("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –≥–æ—Ä–æ–¥–∞:", reply_markup=cancel_keyboard())

@dp.message(F.text == "üåç –ü–µ—Ä–µ–≤–æ–¥")
async def translate_handler(message: Message, state: FSMContext):
    await state.set_state(Form.translate)
    await message.answer("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:", reply_markup=cancel_keyboard())


# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–≥–æ–¥—ã ---
@dp.message(Form.weather)
async def get_weather(message: Message, state: FSMContext):
    city = message.text
    if not WEATHER_API_KEY:
        await message.answer("‚ö†Ô∏è –°–µ—Ä–≤–∏—Å –ø–æ–≥–æ–¥—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
        await state.clear()
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=main_keyboard())
        return

    try:
        async with aiohttp.ClientSession() as session:
            async with session.get(
                f"{BASE_WEATHER_URL}?q={city}&appid={WEATHER_API_KEY}&units=metric&lang=ru"
            ) as response:
                data = await response.json()
                if response.status != 200:
                    await message.answer(f"‚ùå –û—à–∏–±–∫–∞: {data.get('message', '–ì–æ—Ä–æ–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω')}")
                    return

                weather = data["weather"][0]["description"].capitalize()
                temp = data["main"]["temp"]
                humidity = data["main"]["humidity"]
                wind = data["wind"]["speed"]

                response_text = (
                    f"üå§ –ü–æ–≥–æ–¥–∞ –≤ {city}:\n"
                    f"{weather}\n"
                    f"üå° –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞: {temp}¬∞C\n"
                    f"üíß –í–ª–∞–∂–Ω–æ—Å—Ç—å: {humidity}%\n"
                    f"üçÉ –í–µ—Ç–µ—Ä: {wind} –º/—Å"
                )
                await message.answer(response_text)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø–æ–≥–æ–¥—ã: {e}")
        await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–≥–æ–¥—É.")
    finally:
        await state.clear()
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=main_keyboard())

# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ ---
@dp.message(Form.translate)
async def translate_text(message: Message, state: FSMContext):
    text = message.text
    system_prompt = "–ü–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. –°–æ—Ö—Ä–∞–Ω–∏ —Å–º—ã—Å–ª –∏ —Å—Ç–∏–ª—å. –ë–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π."

    await ai_response(message, system_prompt, text)
    await state.clear()
    await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=main_keyboard())

# >>> ADD: –≤—ã–±–æ—Ä –≥–æ–ª–æ—Å–∞ (—Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS.choosing_voice)
@dp.message(TTS.choosing_voice)
async def choose_voice(message: Message, state: FSMContext):
    user_choice = message.text.strip()
    data = await state.get_data()
    voices_map = data.get("voices_map", {})

    if user_choice not in voices_map:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∫–Ω–æ–ø–∫–æ–π –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚ùå –û—Ç–º–µ–Ω–∞¬ª.")
        return

    voice_id = voices_map[user_choice]
    await state.update_data(selected_voice_id=voice_id, selected_voice_name=user_choice)
    await state.set_state(TTS.waiting_text)
    await message.answer(
        f"‚úÖ –ì–æ–ª–æ—Å ¬´{user_choice}¬ª –≤—ã–±—Ä–∞–Ω.\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ–∑–≤—É—á–∏—Ç—å.",
        reply_markup=cancel_keyboard()
    )

# >>> ADD: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ (—Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS.waiting_text)
@dp.message(TTS.waiting_text)
async def tts_generate_and_send(message: Message, state: FSMContext):
    text = (message.text or "").strip()
    if not text:
        await message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ–ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
        return

    data = await state.get_data()
    voice_id = data.get("selected_voice_id")
    voice_name = data.get("selected_voice_name", "voice")

    if not voice_id:
        await message.answer("–ù–µ –Ω–∞–π–¥–µ–Ω –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ: /start")
        await state.clear()
        return

    try:
        # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ò–ú–ï–ù–ê –§–ê–ô–õ–û–í + –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏
        base = f"{message.from_user.id}_{time.time_ns()}"
        mp3_path = os.path.abspath(os.path.join(AUDIO_DIR, f"{base}.mp3"))
        ogg_path = os.path.abspath(os.path.join(AUDIO_DIR, f"{base}.ogg"))

        # 1) –ì–µ–Ω–µ—Ä–∞—Ü–∏—è MP3 (–ò–ú–ï–ù–ù–û –≤ mp3_path, –∞ –Ω–µ 'audio.mp3')
        await voice_async.generate_audio(text=text, voice_id=voice_id, out_name=mp3_path)

        # 2) –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Ä–µ–∞–ª—å–Ω–æ —Å–æ–∑–¥–∞–Ω
        if not os.path.exists(mp3_path) or os.path.getsize(mp3_path) == 0:
            logging.error(f"MP3 –Ω–µ —Å–æ–∑–¥–∞–Ω: {mp3_path}")
            await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ-—Ñ–∞–π–ª. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.")
            return

        # 3) –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OGG (Opus) –¥–ª—è voice
        try:
            mp3_to_ogg_opus(mp3_path, ogg_path)
        except Exception as conv_err:
            logging.error(f"OGG convert error: {conv_err}")
            await message.answer("–ê—É–¥–∏–æ —Å–æ–∑–¥–∞–Ω–æ, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–¥–µ–ª–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ. –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–æ–ª—å–∫–æ mp3.")

        # 4) –û—Ç–ø—Ä–∞–≤–ª—è–µ–º MP3
        await message.answer_audio(
            audio=FSInputFile(mp3_path),
            caption=f"üéß –û–∑–≤—É—á–∫–∞ –≥–æ–ª–æ—Å–æ–º {voice_name}",
        )

        # 5) –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–æ—Å—å ‚Äî –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∏ voice (OGG)
        if os.path.exists(ogg_path) and os.path.getsize(ogg_path) > 0:
            await message.answer_voice(
                voice=FSInputFile(ogg_path),
                caption=f"üéôÔ∏è –ì–æ–ª–æ—Å–æ–≤–æ–µ (Opus) ‚Äî {voice_name}",
            )

    except Exception as e:
        logging.error(f"TTS error: {e}", exc_info=True)
        msg = str(e)
        if "detected_unusual_activity" in msg:
            await message.answer(
                "‚ùå ElevenLabs –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª Free-—Ç–∞—Ä–∏—Ñ (detected_unusual_activity). "
                "–ü–æ–¥–∫–ª—é—á–∏—Ç–µ –ø–ª–∞—Ç–Ω—É—é –ø–æ–¥–ø–∏—Å–∫—É –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∫–ª—é—á/–¥–≤–∏–∂–æ–∫."
            )
        elif "voice_not_found" in msg or "404" in msg:
            await message.answer(
                "‚ö†Ô∏è –≠—Ç–æ—Ç –≥–æ–ª–æ—Å —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –¥—Ä—É–≥–æ–π –≥–æ–ª–æ—Å."
            )
            voices = await voice_async.get_all_voices()
            await state.update_data(voices_map={v["name"]: v["id"] for v in voices})
            await state.set_state(TTS.choosing_voice)
            await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:", reply_markup=voices_keyboard(voices))
            return
        else:
            await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á/–ø–æ–¥–ø–∏—Å–∫—É ElevenLabs.")
    finally:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –æ—Å—Ç–∞–ª–∏—Å—å –≤ –≤—ã–±–æ—Ä–µ –≥–æ–ª–æ—Å–∞
        curr = await state.get_state()
        if curr != TTS.choosing_voice:
            await state.clear()
            await message.answer("–ì–æ—Ç–æ–≤–æ. –í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=main_keyboard())

@router.message()
async def handle_message(message: Message):
    # ... –≤–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —á–∞—Ç–∞ —Å OpenAI ...
    pass

async def main():
    dp.include_router(router)
    await dp.start_polling(bot)

if __name__ == "__main__":
    restore_user_data()
    asyncio.run(main())
