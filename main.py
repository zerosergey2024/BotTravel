# ... –≤–∞—à–∏ –∏–º–ø–æ—Ä—Ç—ã ...
import logging
import os
import aiohttp
import asyncio
from pathlib import Path
from aiogram import Bot, Dispatcher, types
from aiogram.types import Message, FSInputFile
from aiogram import Router, F
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import StatesGroup, State
from aiogram.utils.keyboard import ReplyKeyboardBuilder
from openai import AsyncOpenAI
from dotenv import load_dotenv
from aiogram.fsm.storage.memory import MemoryStorage

# >>> ADD: –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º pydub –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∏ –Ω–∞—à –º–æ–¥—É–ª—å voice
from pydub import AudioSegment
import voice_async
# ---

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()]
)

load_dotenv()

BASE_DIR = Path(__file__).parent.parent
DATA_DIR = os.path.abspath(os.path.join(os.getcwd(), "data"))
DOWNLOADS_DIR = os.path.abspath(os.path.join(os.getcwd(), "downloads"))
AUDIO_DIR = os.path.abspath(os.path.join(os.getcwd(), "audio"))  # >>> ADD

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(DOWNLOADS_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)  # >>> ADD

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
API_KEY = os.getenv("API_KEY")
WEATHER_API_KEY = os.getenv("WEATHER_API_KEY")
BASE_WEATHER_URL = "https://api.openweathermap.org/data/2.5/weather"

if not TELEGRAM_BOT_TOKEN:
    logging.error("‚ùå TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
    exit(1)
else:
    logging.info("‚úÖ TELEGRAM_BOT_TOKEN —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")

if not WEATHER_API_KEY:
    logging.warning("‚ö†Ô∏è WEATHER_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω ‚Äî —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–≥–æ–¥—ã –æ—Ç–∫–ª—é—á–µ–Ω—ã.")

bot = Bot(token=TELEGRAM_BOT_TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)
router = Router()

client = AsyncOpenAI(
    api_key=API_KEY,
    base_url="https://api.openai.com/v1",
)

user_data = {}

# >>> ADD: –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ mp3 -> ogg (opus)
def mp3_to_ogg_opus(mp3_path: str, ogg_path: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç mp3 –≤ ogg (Opus) –¥–ª—è voice-—Å–æ–æ–±—â–µ–Ω–∏—è Telegram.
    –¢—Ä–µ–±—É–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ ffmpeg –≤ —Å–∏—Å—Ç–µ–º–µ.
    """
    audio = AudioSegment.from_file(mp3_path, format="mp3")
    # Telegram —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç ~48kbps opus –¥–ª—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö, –Ω–æ —ç—Ç–æ –Ω–µ —Å—Ç—Ä–æ–≥–æ.
    audio.export(ogg_path, format="ogg", codec="libopus", bitrate="48k")
    return ogg_path
# ---

def restore_user_data():
    # ... –∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ ...
    pass  # (–æ—Å—Ç–∞–≤—å—Ç–µ –≤–∞—à—É —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é, —è –æ–ø—É—Å–∫–∞—é –∑–¥–µ—Å—å —Ä–∞–¥–∏ –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏)

def process_text_file(file_path):
    # ... –∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ ...
    pass

def save_user_data(user_id: int, data_type: str, content: str):
    # ... –∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ ...
    pass

def load_user_data(user_id, data_type):
    # ... –∫–∞–∫ —É –≤–∞—Å –±—ã–ª–æ ...
    pass

# --- –ö–ª–∞–≤–∏–∞—Ç—É—Ä—ã ---
def main_keyboard():
    builder = ReplyKeyboardBuilder()
    builder.add(types.KeyboardButton(text="üéôÔ∏è –û–∑–≤—É—á–∫–∞"))
    builder.add(types.KeyboardButton(text="üå§Ô∏è –ü–æ–≥–æ–¥–∞"))
    builder.add(types.KeyboardButton(text="üåç –ü–µ—Ä–µ–≤–æ–¥"))
    return builder.as_markup(resize_keyboard=True)

def cancel_keyboard():
    builder = ReplyKeyboardBuilder()
    builder.add(types.KeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞"))
    return builder.as_markup(resize_keyboard=True)

# >>> ADD: –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∞ –≥–æ–ª–æ—Å–∞ (reply)
def voices_keyboard(voices: list[dict]):
    """
    voices: [{'name': str, 'id': str}, ...]
    """
    builder = ReplyKeyboardBuilder()
    # –†–∞–∑–ª–æ–∂–∏–º –∫–Ω–æ–ø–∫–∏ –ø–æ 2-3 –≤ —Ä—è–¥:
    for v in voices:
        # –ù–∞ —Å–ª—É—á–∞–π –∫–æ–ª–ª–∏–∑–∏–π –∏–º—ë–Ω –¥–æ–±–∞–≤–∏–º —Ö–≤–æ—Å—Ç –∏–∑ id
        name = v["name"]
        builder.add(types.KeyboardButton(text=name))
    builder.add(types.KeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞"))
    builder.adjust(2)
    return builder.as_markup(resize_keyboard=True)
# ---

# --- FSM States ---
class Form(StatesGroup):
    weather = State()
    translate = State()

# >>> ADD: —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è TTS
class TTS(StatesGroup):
    choosing_voice = State()
    waiting_text = State()
# ---

@router.message(Command("start"))
async def start_command(message: Message, state: FSMContext):
    try:
        # –ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–∞ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—ã–±–æ—Ä
        voices = await voice_async.get_all_voices()  # [{'name','id'},...]
        # –°–æ—Ö—Ä–∞–Ω–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–º—è->id –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —é–∑–µ—Ä–∞
        await state.update_data(voices_map={v["name"]: v["id"] for v in voices})
        await state.set_state(TTS.choosing_voice)

        photo = None
        try:
            photo = FSInputFile('img/–§–æ—Ç–æ–ë–æ—Ç1.jpg')
        except Exception:
            pass

        text = (
            "–ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à AI-–ø–æ–º–æ—â–Ω–∏–∫. –í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –¥–ª—è –æ–∑–≤—É—á–∫–∏, –∞ –∑–∞—Ç–µ–º –ø—Ä–∏—à–ª–∏—Ç–µ —Ç–µ–∫—Å—Ç.\n\n"
            "–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:"
        )

        if photo:
            await message.answer_photo(
                photo=photo,
                caption=text,
                reply_markup=voices_keyboard(voices)
            )
        else:
            await message.answer(text, reply_markup=voices_keyboard(voices))
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ /start: {e}")
        await message.answer("–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?", reply_markup=main_keyboard())

# >>> ADD: –æ—Ç–¥–µ–ª—å–Ω–∞—è –∫–Ω–æ–ø–∫–∞ –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é –¥–ª—è –æ–∑–≤—É—á–∫–∏
@dp.message(F.text == "üéôÔ∏è –û–∑–≤—É—á–∫–∞")
async def tts_entry(message: Message, state: FSMContext):
    try:
        voices = await voice_async.get_all_voices()
        await state.update_data(voices_map={v["name"]: v["id"] for v in voices})
        await state.set_state(TTS.choosing_voice)
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å:", reply_markup=voices_keyboard(voices))
    except Exception as e:
        logging.error(f"TTS entry error: {e}")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤.", reply_markup=main_keyboard())
# ---

@router.message(F.document)
async def handle_document(message: Message):
    # ... –≤–∞—à –∫–æ–¥ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
    pass

@router.message(Command("instruction"))
async def show_instruction(message: Message):
    # ... –≤–∞—à –∫–æ–¥ ...
    pass

@router.message(Command("knowledge"))
async def show_knowledge(message: Message):
    # ... –≤–∞—à –∫–æ–¥ ...
    pass

@dp.message(F.text == "‚ùå –û—Ç–º–µ–Ω–∞")
async def cancel_handler(message: Message, state: FSMContext):
    await state.clear()
    await message.answer("–î–µ–π—Å—Ç–≤–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ", reply_markup=main_keyboard())

@dp.message(F.text == "üå§Ô∏è –ü–æ–≥–æ–¥–∞")
async def weather_handler(message: Message, state: FSMContext):
    # ... –≤–∞—à –∫–æ–¥ ...
    pass

@dp.message(F.text == "üåç –ü–µ—Ä–µ–≤–æ–¥")
async def translate_handler(message: Message, state: FSMContext):
    # ... –≤–∞—à –∫–æ–¥ ...
    pass

@dp.message(Form.weather)
async def get_weather(message: Message, state: FSMContext):
    # ... –≤–∞—à –∫–æ–¥ ...
    pass

@dp.message(Form.translate)
async def translate_text(message: Message, state: FSMContext):
    # ... –≤–∞—à –∫–æ–¥ ...
    pass

# >>> ADD: –≤—ã–±–æ—Ä –≥–æ–ª–æ—Å–∞ (—Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS.choosing_voice)
@dp.message(TTS.choosing_voice)
async def choose_voice(message: Message, state: FSMContext):
    user_choice = message.text.strip()
    data = await state.get_data()
    voices_map = data.get("voices_map", {})

    if user_choice not in voices_map:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –≥–æ–ª–æ—Å –∫–Ω–æ–ø–∫–æ–π –Ω–∞ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ –∏–ª–∏ –Ω–∞–∂–º–∏—Ç–µ ¬´‚ùå –û—Ç–º–µ–Ω–∞¬ª.")
        return

    voice_id = voices_map[user_choice]
    await state.update_data(selected_voice_id=voice_id, selected_voice_name=user_choice)
    await state.set_state(TTS.waiting_text)
    await message.answer(
        f"‚úÖ –ì–æ–ª–æ—Å ¬´{user_choice}¬ª –≤—ã–±—Ä–∞–Ω.\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –Ω—É–∂–Ω–æ –æ–∑–≤—É—á–∏—Ç—å.",
        reply_markup=cancel_keyboard()
    )

# >>> ADD: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–∫–∞ –∞—É–¥–∏–æ (—Å–æ—Å—Ç–æ—è–Ω–∏–µ TTS.waiting_text)
@dp.message(TTS.waiting_text)
async def tts_generate_and_send(message: Message, state: FSMContext):
    text = message.text.strip()
    if not text:
        await message.answer("–ü—Ä–∏—à–ª–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–µ–ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç.")
        return

    data = await state.get_data()
    voice_id = data.get("selected_voice_id")
    voice_name = data.get("selected_voice_name", "voice")

    if not voice_id:
        await message.answer("–ù–µ –Ω–∞–π–¥–µ–Ω –≤—ã–±—Ä–∞–Ω–Ω—ã–π –≥–æ–ª–æ—Å. –ù–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ: /start")
        await state.clear()
        return

    try:
        # –ò–º–µ–Ω–∞ —Ñ–∞–π–ª–æ–≤ ‚Äî —Å user_id –∏ –≤—Ä–µ–º–µ–Ω–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–ª–∏—Å—å
        base = f"{message.from_user.id}_{int(asyncio.get_event_loop().time()*1000)}"
        mp3_path = os.path.join(AUDIO_DIR, f"{base}.mp3")
        ogg_path = os.path.join(AUDIO_DIR, f"{base}.ogg")

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ ElevenLabs (MP3)
        await voice_async.generate_audio("–ü—Ä–∏–≤–µ—Ç!", voice_id, "audio.mp3")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ OGG (Opus) –¥–ª—è voice
        mp3_to_ogg_opus(mp3_path, ogg_path)

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –∞—É–¥–∏–æ (mp3)
        await message.answer_audio(
            audio=FSInputFile(mp3_path),
            caption=f"üéß –û–∑–≤—É—á–∫–∞ –≥–æ–ª–æ—Å–æ–º {voice_name}"
        )

        # –ò –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –≥–æ–ª–æ—Å–æ–≤–æ–µ (ogg/opus)
        await message.answer_voice(
            voice=FSInputFile(ogg_path),
            caption=f"üéôÔ∏è –ì–æ–ª–æ—Å–æ–≤–æ–µ (Opus) ‚Äî {voice_name}"
        )

    except Exception as e:
        logging.error(f"TTS error: {e}")
        await message.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–ª—é—á ElevenLabs –∏ –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
    finally:
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
        await state.clear()
        await message.answer("–ì–æ—Ç–æ–≤–æ. –í—ã–±–µ—Ä–∏—Ç–µ —Å–ª–µ–¥—É—é—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ:", reply_markup=main_keyboard())

@router.message()
async def handle_message(message: Message):
    # ... –≤–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —á–∞—Ç–∞ —Å OpenAI ...
    pass

async def main():
    dp.include_router(router)
    await dp.start_polling(bot)

if __name__ == "__main__":
    restore_user_data()
    asyncio.run(main())
